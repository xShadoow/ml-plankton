{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e70897",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Plancton Images Classifier</span>\n",
    "*von Bourges Julian, Hahn Sandro, Schmalzl Maximilian*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: \n",
    "Plankton ist die Bezeichnung für die Gesamtheit der Organismen, die im Wasser von Meeren, Flüssen und Seen leben. Sie bewegen sich nicht oder nur sehr wenig aus eigener Kraft, weshalb deren Schwimmrichtung von der Strömung vorgegeben wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766c0b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:rgb(166, 212, 46)\">I. Datenvorbereitung</span>\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Datensatz \"Converted\" besteht aus 219 063 .png Dateien. Jede einzelne .png bildet ein Plankton ab. Um mit diesem Datensatz arbeiten zu können, müssen die einzelnen Daten, also die .png Bilder, zunächst aufbereitet und skaliert werden. <br> \n",
    "Da Java-Code direkt in Maschinencode kompiliert wird, ist er in der Regel schneller. Unsere Daten haben wir deshalb zunächst mit Java genauer betrachtet und aufbereitet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen Eindruck von der Größe der Bilder zu bekommen haben wir mit der getPercentages()-Funktion die Anzahl der Pixel berechnet, in die die einzelnen Bilder jeweils in Höhe und Breite skaliert sind. Anschließend haben wir die Bilder mit 0 - 99, 100 - 199, ... und 1300 - 1399 Pixeln zu Gruppen zusammengefast und uns die jeweilige Repräsentation der Gruppe in Prozent ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [],
   "source": [
    "public static void getPercentages() {\n",
    "\n",
    "        DecimalFormat df = new DecimalFormat(\"0.00\");\n",
    "        int sum = 0;\n",
    "\n",
    "        for(int entry : WIDTHS_ARR) {\n",
    "            sum += entry;\n",
    "        }\n",
    "\n",
    "        System.out.println(\"Widths:\");\n",
    "\n",
    "        for(int i = 0; i < WIDTHS_ARR.length; i++) {\n",
    "            double percent = ((double) WIDTHS_ARR[i] / sum) * 100.0D;\n",
    "            System.out.println(i + \": \" + WIDTHS_ARR[i] + \" (\" + df.format(percent) + \"%)\");\n",
    "        }\n",
    "\n",
    "        System.out.println();\n",
    "        System.out.println(\"Heights:\");\n",
    "\n",
    "        for(int i = 0; i < HEIGHTS_ARR.length; i++) {\n",
    "            double percent = ((double) HEIGHTS_ARR[i] / sum) * 100.0D;\n",
    "            System.out.println(i + \": \" + HEIGHTS_ARR[i] + \" (\" + df.format(percent) + \"%)\");\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion erzeugt folgenden Output (ersichtlicher dargestellt in einer Tabelle):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Widths</th>\n",
    "    <th>Counts</th>\n",
    "    <th></th>\n",
    "    <th>Heights</th>\n",
    "    <th>Counts</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>21592 (9,86%)</td>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>19926 (9,10%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>72812 (33,24%)</td>\n",
    "    <td></td>\n",
    "    <td>1</td>\n",
    "    <td>60609 (27,67%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>93711 (42,78%)</td>\n",
    "    <td></td>\n",
    "    <td>2</td>\n",
    "    <td>99519 (45,43%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>15954 (7,28%)</td>\n",
    "    <td></td>\n",
    "    <td>3</td>\n",
    "    <td>19706 (9,00%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>7324 (3,34%)</td>\n",
    "    <td></td>\n",
    "    <td>4</td>\n",
    "    <td>9451 (4,31%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>3609 (1,65%)</td>\n",
    "    <td></td>\n",
    "    <td>5</td>\n",
    "    <td>4675 (2,13%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>1838 (0,84%)</td>\n",
    "    <td></td>\n",
    "    <td>6</td>\n",
    "    <td>2415 (1,10%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>973 (0,44%)</td>\n",
    "    <td></td>\n",
    "    <td>7</td>\n",
    "    <td>1297 (0,59%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>8</td>\n",
    "    <td>558 (0,25%)</td>\n",
    "    <td></td>\n",
    "    <td>8</td>\n",
    "    <td>692 (0,32%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>9</td>\n",
    "    <td>317 (0,14%)</td>\n",
    "    <td></td>\n",
    "    <td>9</td>\n",
    "    <td>380 (0,17%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>213 (0,10%)</td>\n",
    "    <td></td>\n",
    "    <td>10</td>\n",
    "    <td>287 (0,13%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11</td>\n",
    "    <td>74 (0,03%)</td>\n",
    "    <td></td>\n",
    "    <td>11</td>\n",
    "    <td>47 (0,02%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>12</td>\n",
    "    <td>34 (0,02%)</td>\n",
    "    <td></td>\n",
    "    <td>12</td>\n",
    "    <td>20 (0,01%)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>13</td>\n",
    "    <td>53 (0,02%)</td>\n",
    "    <td></td>\n",
    "    <td>13</td>\n",
    "    <td>38 (0,02%)</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass, sowohl in Breite und Höhe, die meist repräsentierte Gruppe 200 - 299 Pixel groß ist. Gedicht gefolgt von der Gruppe mit 100 - 199 Pixeln. Alle anderen Gruppen beinhalten relativ wenige Bilder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit können wir folgendes machen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [],
   "source": [
    "public static void resizeAll() throws Exception {\n",
    "\n",
    "    final String inputRootPath = \"D://KI_Plankton//Plankton_Converted//Converted\";\n",
    "    final String outputRootPath = \"D://KI_Plankton//Output200//\";\n",
    "    final int targetWidth = 200;\n",
    "    final int targetHeight = 200;\n",
    "\n",
    "    File rootDir = new File(inputRootPath);\n",
    "    int i = 0;\n",
    "\n",
    "    for(String pictureName : rootDir.list()) {\n",
    "\n",
    "        File input = new File(inputRootPath + \"//\" + pictureName);\n",
    "        File output = new File(outputRootPath + pictureName);\n",
    "        resizeImage(targetWidth, targetHeight, input, output);\n",
    "\n",
    "        if(++i % 1_000 == 0) {\n",
    "            System.out.println(\"processed \" + i + \" pictures\");\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "public static void resizeImage(int targetWidth, int targetHeight, File input, File output) throws Exception {\n",
    "\n",
    "    BufferedImage bufferedImage = ImageIO.read(input);\n",
    "\n",
    "    boolean fitHeight = bufferedImage.getHeight() > bufferedImage.getWidth();\n",
    "    Scalr.Mode scaleMode = fitHeight ? Scalr.Mode.FIT_TO_HEIGHT : Scalr.Mode.FIT_TO_WIDTH;\n",
    "\n",
    "    BufferedImage scaledImage = resizeImage(bufferedImage, targetWidth, targetHeight, scaleMode);\n",
    "\n",
    "    int y_val = (int) ((targetHeight/2.0D) - (scaledImage.getHeight()/2.0D));\n",
    "    int x_val = (int) ((targetWidth/2.0D) - (scaledImage.getWidth()/2.0D));\n",
    "\n",
    "    BufferedImage newImage = new BufferedImage(targetWidth, targetHeight, BufferedImage.TYPE_INT_RGB);\n",
    "    Graphics2D graphics2D = newImage.createGraphics();\n",
    "    graphics2D.setPaint(new Color(0, 0, 0));\n",
    "    graphics2D.fillRect(0, 0, newImage.getWidth(), newImage.getHeight());\n",
    "\n",
    "    if(fitHeight) {\n",
    "        graphics2D.drawImage(scaledImage, x_val, 0, null);\n",
    "    } else {\n",
    "        graphics2D.drawImage(scaledImage, 0, y_val, null);\n",
    "    }\n",
    "\n",
    "    graphics2D.dispose();\n",
    "    ImageIO.write(newImage, \"png\" , output);\n",
    "\n",
    "}\n",
    "\n",
    "public static BufferedImage resizeImage(BufferedImage originalImage, int targetWidth, int targetHeight, Scalr.Mode mode) throws Exception {\n",
    "    Scalr.Method method = Scalr.Method.QUALITY;\n",
    "    return Scalr.resize(originalImage, method, mode, targetWidth, targetHeight, Scalr.OP_ANTIALIAS);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Beispiel: Anzahl der Klassen (Anpassen Sie dies entsprechend Ihren Daten)\n",
    "num_classes = 10\n",
    "\n",
    "# Erstellen Sie ein sequentielles Modell\n",
    "model = Sequential()\n",
    "\n",
    "# Fügen Sie Schichten zum Modell hinzu\n",
    "model.add(Dense(128, input_shape=(input_size,), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Kompilieren Sie das Modell\n",
    "model.compile(loss='categorical_crossentropy',  # Anpassen Sie dies entsprechend Ihrem Problem\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Zeigen Sie eine Zusammenfassung des Modells an\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Covolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Beispiel: Bildgröße und Anzahl der Klassen (Anpassen Sie dies entsprechend Ihren Daten)\n",
    "img_size = (64, 64, 3)  # Hier angenommen, dass die Bilder 64x64 Pixel mit 3 Farbkanälen sind\n",
    "num_classes = 10\n",
    "\n",
    "# Erstellen Sie ein sequentielles Modell\n",
    "model = Sequential()\n",
    "\n",
    "# Fügen Sie Convolutional- und Pooling-Schichten hinzu\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=img_size))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flach machen (flatten) Sie die Ausgabe für den Fully Connected Teil\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fügen Sie Dense-Schichten für die Klassifikation hinzu\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Kompilieren Sie das Modell\n",
    "model.compile(loss='categorical_crossentropy',  # Anpassen Sie dies entsprechend Ihrem Problem\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Zeigen Sie eine Zusammenfassung des Modells an\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
